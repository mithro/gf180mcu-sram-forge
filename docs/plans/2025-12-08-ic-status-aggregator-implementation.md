# IC Status Aggregator Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Add `sram-forge downstream` CLI commands to aggregate GitHub Actions status across all downstream IC repos and publish to GitHub Pages.

**Architecture:** New `status/` module fetches workflow data via `gh` CLI, groups runs by sram-forge revision, outputs to terminal/markdown/JSON/HTML. Config file `downstream_repos.yaml` is single source of truth for both CLI and GitHub Actions workflows.

**Tech Stack:** Click CLI, Pydantic models, Jinja2 templates, `gh` CLI for GitHub API

---

## Task 1: Create Downstream Repos Config File

**Files:**
- Create: `sram_forge/db/data/downstream_repos.yaml`

**Step 1: Create the config file**

```yaml
# Downstream IC repositories generated by sram-forge
# This file is the single source of truth used by:
# - sram-forge downstream list/matrix/status commands
# - .github/workflows/update-downstream.yml

repos:
  - name: gf180mcu-ic-0p5x0p5-sram-u8b3k
    owner: mithro
    sram: u8b3k
    slot: 0p5x0p5
    config: examples/sram_0p5x0p5_u8b3k.yaml
    deploy_key_secret: DEPLOY_KEY_0P5X0P5

  - name: gf180mcu-ic-0p5x1-sram-u8b8k
    owner: mithro
    sram: u8b8k
    slot: 0p5x1
    config: examples/sram_0p5x1_u8b8k.yaml
    deploy_key_secret: DEPLOY_KEY_0P5X1

  - name: gf180mcu-ic-1x0p5-sram-u8b9k
    owner: mithro
    sram: u8b9k
    slot: 1x0p5
    config: examples/sram_1x0p5_u8b9k.yaml
    deploy_key_secret: DEPLOY_KEY_1X0P5

  - name: gf180mcu-ic-1x1-sram-u8b24k
    owner: mithro
    sram: u8b24k
    slot: 1x1
    config: examples/sram_1x1_u8b24k.yaml
    deploy_key_secret: DEPLOY_KEY_1X1
```

**Step 2: Commit**

```bash
git add sram_forge/db/data/downstream_repos.yaml
git commit -m "feat: add downstream repos config file

Single source of truth for downstream IC repositories.
Used by CLI commands and GitHub Actions workflows."
```

---

## Task 2: Create DownstreamRepo Model

**Files:**
- Create: `sram_forge/models/downstream.py`
- Modify: `sram_forge/models/__init__.py`
- Create: `sram_forge/tests/test_models_downstream.py`

**Step 1: Write the failing test**

Create `sram_forge/tests/test_models_downstream.py`:

```python
"""Tests for downstream repository models."""

import pytest

from sram_forge.models.downstream import DownstreamRepo


def test_downstream_repo_from_dict():
    """DownstreamRepo can be created from dict."""
    data = {
        "name": "gf180mcu-ic-1x1-sram-u8b24k",
        "owner": "mithro",
        "sram": "u8b24k",
        "slot": "1x1",
        "config": "examples/sram_1x1_u8b24k.yaml",
        "deploy_key_secret": "DEPLOY_KEY_1X1",
    }
    repo = DownstreamRepo.model_validate(data)

    assert repo.name == "gf180mcu-ic-1x1-sram-u8b24k"
    assert repo.owner == "mithro"
    assert repo.sram == "u8b24k"
    assert repo.slot == "1x1"
    assert repo.config == "examples/sram_1x1_u8b24k.yaml"
    assert repo.deploy_key_secret == "DEPLOY_KEY_1X1"


def test_downstream_repo_full_name():
    """DownstreamRepo provides full GitHub repo name."""
    data = {
        "name": "gf180mcu-ic-1x1-sram-u8b24k",
        "owner": "mithro",
        "sram": "u8b24k",
        "slot": "1x1",
        "config": "examples/sram_1x1_u8b24k.yaml",
        "deploy_key_secret": "DEPLOY_KEY_1X1",
    }
    repo = DownstreamRepo.model_validate(data)

    assert repo.full_name == "mithro/gf180mcu-ic-1x1-sram-u8b24k"
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest sram_forge/tests/test_models_downstream.py -v`
Expected: FAIL with "No module named 'sram_forge.models.downstream'"

**Step 3: Write the model**

Create `sram_forge/models/downstream.py`:

```python
"""Models for downstream IC repositories."""

from pydantic import BaseModel, computed_field


class DownstreamRepo(BaseModel):
    """A downstream IC repository generated by sram-forge."""

    name: str
    """Repository name (e.g., 'gf180mcu-ic-1x1-sram-u8b24k')."""

    owner: str
    """GitHub owner/organization (e.g., 'mithro')."""

    sram: str
    """SRAM identifier for display (e.g., 'u8b24k')."""

    slot: str
    """Slot size (e.g., '1x1', '0p5x0p5')."""

    config: str
    """Path to chip config YAML in sram-forge repo."""

    deploy_key_secret: str
    """GitHub Actions secret name for deploy key."""

    @computed_field
    @property
    def full_name(self) -> str:
        """Full GitHub repository name (owner/repo)."""
        return f"{self.owner}/{self.name}"
```

**Step 4: Update models __init__.py**

Add to `sram_forge/models/__init__.py`:

```python
from sram_forge.models.downstream import DownstreamRepo
```

Add `DownstreamRepo` to the `__all__` list if one exists.

**Step 5: Run test to verify it passes**

Run: `uv run pytest sram_forge/tests/test_models_downstream.py -v`
Expected: PASS (2 tests)

**Step 6: Commit**

```bash
git add sram_forge/models/downstream.py sram_forge/models/__init__.py sram_forge/tests/test_models_downstream.py
git commit -m "feat: add DownstreamRepo model

Pydantic model for downstream IC repository configuration."
```

---

## Task 3: Add Loader for Downstream Repos

**Files:**
- Modify: `sram_forge/db/loader.py`
- Modify: `sram_forge/tests/test_db_loader.py`

**Step 1: Write the failing test**

Add to `sram_forge/tests/test_db_loader.py`:

```python
def test_load_downstream_repos(sample_data_dir):
    """Load downstream repos from YAML."""
    from sram_forge.db.loader import load_downstream_repos

    repos = load_downstream_repos(sample_data_dir / "downstream_repos.yaml")

    assert len(repos) >= 1
    assert all(hasattr(r, "name") for r in repos)
    assert all(hasattr(r, "full_name") for r in repos)


def test_load_downstream_repos_from_bundled():
    """Load downstream repos from bundled data."""
    from pathlib import Path
    from sram_forge.db.loader import load_downstream_repos

    bundled_path = Path(__file__).parent.parent / "db" / "data" / "downstream_repos.yaml"
    repos = load_downstream_repos(bundled_path)

    assert len(repos) == 4
    sram_names = [r.sram for r in repos]
    assert "u8b3k" in sram_names
    assert "u8b8k" in sram_names
    assert "u8b9k" in sram_names
    assert "u8b24k" in sram_names
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest sram_forge/tests/test_db_loader.py::test_load_downstream_repos -v`
Expected: FAIL with "cannot import name 'load_downstream_repos'"

**Step 3: Write the loader function**

Add to `sram_forge/db/loader.py`:

```python
from sram_forge.models.downstream import DownstreamRepo


def load_downstream_repos(path: Path) -> list[DownstreamRepo]:
    """Load downstream repository configurations from YAML.

    Args:
        path: Path to downstream_repos.yaml file

    Returns:
        List of DownstreamRepo objects
    """
    with open(path) as f:
        data = yaml.safe_load(f)

    return [DownstreamRepo.model_validate(r) for r in data["repos"]]
```

**Step 4: Create test fixture data**

Create `sram_forge/tests/fixtures/downstream_repos.yaml` (or use the real file path in conftest):

```yaml
repos:
  - name: test-repo
    owner: test-owner
    sram: u8b1k
    slot: 1x1
    config: examples/test.yaml
    deploy_key_secret: TEST_KEY
```

Update `conftest.py` to include fixture if needed.

**Step 5: Run tests to verify they pass**

Run: `uv run pytest sram_forge/tests/test_db_loader.py -v -k downstream`
Expected: PASS

**Step 6: Commit**

```bash
git add sram_forge/db/loader.py sram_forge/tests/test_db_loader.py
git commit -m "feat: add load_downstream_repos loader function"
```

---

## Task 4: Create Status Models

**Files:**
- Create: `sram_forge/status/__init__.py`
- Create: `sram_forge/status/models.py`
- Create: `sram_forge/tests/test_status_models.py`

**Step 1: Write the failing test**

Create `sram_forge/tests/test_status_models.py`:

```python
"""Tests for status report models."""

from datetime import datetime, timezone

import pytest

from sram_forge.status.models import WorkflowRun, ForgeRevision, StatusReport


def test_workflow_run_from_dict():
    """WorkflowRun can be created from dict."""
    data = {
        "repo": "mithro/gf180mcu-ic-1x1-sram-u8b24k",
        "sram": "u8b24k",
        "slot": "1x1",
        "workflow_name": "CI",
        "status": "completed",
        "conclusion": "success",
        "run_id": 12345,
        "head_sha": "abc1234",
        "updated_at": "2025-12-08T10:00:00Z",
        "html_url": "https://github.com/mithro/gf180mcu-ic-1x1-sram-u8b24k/actions/runs/12345",
        "forge_sha": "def5678",
        "forge_run_id": 67890,
    }
    run = WorkflowRun.model_validate(data)

    assert run.repo == "mithro/gf180mcu-ic-1x1-sram-u8b24k"
    assert run.conclusion == "success"
    assert run.is_success


def test_workflow_run_is_success():
    """WorkflowRun.is_success reflects conclusion."""
    success_run = WorkflowRun(
        repo="owner/repo", sram="u8b1k", slot="1x1", workflow_name="CI",
        status="completed", conclusion="success", run_id=1, head_sha="abc",
        updated_at=datetime.now(timezone.utc), html_url="http://example.com",
        forge_sha=None, forge_run_id=None
    )
    failure_run = WorkflowRun(
        repo="owner/repo", sram="u8b1k", slot="1x1", workflow_name="CI",
        status="completed", conclusion="failure", run_id=2, head_sha="def",
        updated_at=datetime.now(timezone.utc), html_url="http://example.com",
        forge_sha=None, forge_run_id=None
    )

    assert success_run.is_success is True
    assert failure_run.is_success is False


def test_forge_revision_summary():
    """ForgeRevision computes summary correctly."""
    now = datetime.now(timezone.utc)
    runs = [
        WorkflowRun(
            repo="owner/repo1", sram="u8b1k", slot="1x1", workflow_name="CI",
            status="completed", conclusion="success", run_id=1, head_sha="a",
            updated_at=now, html_url="http://example.com",
            forge_sha="abc123", forge_run_id=100
        ),
        WorkflowRun(
            repo="owner/repo2", sram="u8b2k", slot="1x1", workflow_name="CI",
            status="completed", conclusion="failure", run_id=2, head_sha="b",
            updated_at=now, html_url="http://example.com",
            forge_sha="abc123", forge_run_id=100
        ),
    ]

    revision = ForgeRevision(
        forge_sha="abc123",
        forge_run_url="http://example.com/runs/100",
        timestamp=now,
        runs=runs
    )

    assert revision.summary == "1/2"
    assert revision.all_passing is False
    assert revision.passing_count == 1
    assert revision.total_count == 2
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest sram_forge/tests/test_status_models.py -v`
Expected: FAIL with "No module named 'sram_forge.status'"

**Step 3: Create the status module and models**

Create `sram_forge/status/__init__.py`:

```python
"""Status aggregation for downstream IC repositories."""
```

Create `sram_forge/status/models.py`:

```python
"""Models for workflow status reporting."""

from datetime import datetime
from typing import Literal

from pydantic import BaseModel, computed_field


class WorkflowRun(BaseModel):
    """A single GitHub Actions workflow run."""

    repo: str
    """Full repository name (owner/repo)."""

    sram: str
    """SRAM identifier for display."""

    slot: str
    """Slot size."""

    workflow_name: str
    """Name of the workflow."""

    status: Literal["queued", "in_progress", "completed"]
    """Current status of the run."""

    conclusion: Literal["success", "failure", "cancelled", "skipped"] | None
    """Final conclusion (only set when completed)."""

    run_id: int
    """GitHub Actions run ID."""

    head_sha: str
    """Commit SHA in the downstream repo."""

    updated_at: datetime
    """When the run was last updated."""

    html_url: str
    """URL to the workflow run page."""

    forge_sha: str | None
    """sram-forge commit that generated this build (from commit message)."""

    forge_run_id: int | None
    """sram-forge workflow run ID (from commit message)."""

    @computed_field
    @property
    def is_success(self) -> bool:
        """Whether this run succeeded."""
        return self.conclusion == "success"


class ForgeRevision(BaseModel):
    """Workflow runs grouped by sram-forge revision."""

    forge_sha: str
    """The sram-forge commit SHA."""

    forge_run_url: str | None
    """URL to the sram-forge workflow run."""

    timestamp: datetime
    """When this revision was built."""

    runs: list[WorkflowRun]
    """Workflow runs for each downstream repo."""

    @computed_field
    @property
    def passing_count(self) -> int:
        """Number of passing runs."""
        return sum(1 for r in self.runs if r.is_success)

    @computed_field
    @property
    def total_count(self) -> int:
        """Total number of runs."""
        return len(self.runs)

    @computed_field
    @property
    def summary(self) -> str:
        """Summary string like '3/4'."""
        return f"{self.passing_count}/{self.total_count}"

    @computed_field
    @property
    def all_passing(self) -> bool:
        """Whether all runs passed."""
        return self.passing_count == self.total_count


class StatusReport(BaseModel):
    """Complete status report across all downstream repos."""

    generated_at: datetime
    """When this report was generated."""

    revisions: list[ForgeRevision]
    """Revisions, most recent first."""
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest sram_forge/tests/test_status_models.py -v`
Expected: PASS (3 tests)

**Step 5: Commit**

```bash
git add sram_forge/status/__init__.py sram_forge/status/models.py sram_forge/tests/test_status_models.py
git commit -m "feat: add status report models

WorkflowRun, ForgeRevision, and StatusReport Pydantic models
for aggregating GitHub Actions status."
```

---

## Task 5: Create Status Fetcher

**Files:**
- Create: `sram_forge/status/fetcher.py`
- Create: `sram_forge/tests/test_status_fetcher.py`

**Step 1: Write the failing test**

Create `sram_forge/tests/test_status_fetcher.py`:

```python
"""Tests for status fetcher."""

import json
import re
from unittest.mock import patch, MagicMock

import pytest

from sram_forge.status.fetcher import (
    parse_forge_sha_from_message,
    fetch_workflow_runs,
)


def test_parse_forge_sha_from_message():
    """Extract sram-forge SHA from commit message."""
    message = """chore: update generated files from sram-forge

Source commit: abc1234def5678
Workflow run: https://github.com/mithro/gf180mcu-sram-forge/actions/runs/12345"""

    forge_sha, forge_run_id = parse_forge_sha_from_message(message)

    assert forge_sha == "abc1234def5678"
    assert forge_run_id == 12345


def test_parse_forge_sha_from_message_no_match():
    """Handle commit messages without forge info."""
    message = "Initial commit"

    forge_sha, forge_run_id = parse_forge_sha_from_message(message)

    assert forge_sha is None
    assert forge_run_id is None


def test_parse_forge_sha_partial_match():
    """Handle commit messages with only SHA."""
    message = """chore: update

Source commit: deadbeef123"""

    forge_sha, forge_run_id = parse_forge_sha_from_message(message)

    assert forge_sha == "deadbeef123"
    assert forge_run_id is None
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest sram_forge/tests/test_status_fetcher.py -v`
Expected: FAIL with "cannot import name 'parse_forge_sha_from_message'"

**Step 3: Write the fetcher module**

Create `sram_forge/status/fetcher.py`:

```python
"""Fetch workflow status from GitHub via gh CLI."""

import json
import re
import subprocess
from datetime import datetime, timezone

from sram_forge.models.downstream import DownstreamRepo
from sram_forge.status.models import WorkflowRun, ForgeRevision, StatusReport


def parse_forge_sha_from_message(message: str) -> tuple[str | None, int | None]:
    """Extract sram-forge source commit SHA and run ID from commit message.

    Looks for patterns like:
        Source commit: abc1234
        Workflow run: https://github.com/.../actions/runs/12345

    Args:
        message: Git commit message

    Returns:
        Tuple of (forge_sha, forge_run_id), either can be None
    """
    sha_match = re.search(r"Source commit:\s*([a-f0-9]+)", message)
    run_match = re.search(r"/actions/runs/(\d+)", message)

    return (
        sha_match.group(1) if sha_match else None,
        int(run_match.group(1)) if run_match else None,
    )


def fetch_workflow_runs(repo: str, limit: int = 5) -> list[dict]:
    """Fetch latest workflow runs for a repo using gh CLI.

    Args:
        repo: Full repository name (owner/repo)
        limit: Maximum number of runs to fetch

    Returns:
        List of workflow run dicts from gh CLI
    """
    result = subprocess.run(
        [
            "gh", "run", "list",
            "--repo", repo,
            "--limit", str(limit),
            "--json", "workflowName,status,conclusion,databaseId,headSha,updatedAt,url",
        ],
        capture_output=True,
        text=True,
        check=True,
    )
    return json.loads(result.stdout)


def fetch_commit_message(repo: str, sha: str) -> str | None:
    """Fetch commit message for a SHA using gh CLI.

    Args:
        repo: Full repository name (owner/repo)
        sha: Commit SHA

    Returns:
        Commit message or None if fetch fails
    """
    result = subprocess.run(
        [
            "gh", "api",
            f"repos/{repo}/commits/{sha}",
            "--jq", ".commit.message",
        ],
        capture_output=True,
        text=True,
    )
    if result.returncode != 0:
        return None
    return result.stdout.strip()


def fetch_repo_status(
    repo: DownstreamRepo,
    limit: int = 5,
) -> list[WorkflowRun]:
    """Fetch workflow status for a single downstream repo.

    Args:
        repo: Downstream repository config
        limit: Max runs to fetch

    Returns:
        List of WorkflowRun objects
    """
    full_name = repo.full_name
    raw_runs = fetch_workflow_runs(full_name, limit)

    runs = []
    for raw in raw_runs:
        # Get commit message to extract forge SHA
        commit_msg = fetch_commit_message(full_name, raw["headSha"])
        forge_sha, forge_run_id = (None, None)
        if commit_msg:
            forge_sha, forge_run_id = parse_forge_sha_from_message(commit_msg)

        runs.append(WorkflowRun(
            repo=full_name,
            sram=repo.sram,
            slot=repo.slot,
            workflow_name=raw["workflowName"],
            status=raw["status"],
            conclusion=raw.get("conclusion"),
            run_id=raw["databaseId"],
            head_sha=raw["headSha"],
            updated_at=datetime.fromisoformat(raw["updatedAt"].replace("Z", "+00:00")),
            html_url=raw["url"],
            forge_sha=forge_sha,
            forge_run_id=forge_run_id,
        ))

    return runs


def group_by_forge_revision(runs: list[WorkflowRun]) -> list[ForgeRevision]:
    """Group workflow runs by their sram-forge source revision.

    Args:
        runs: List of all workflow runs

    Returns:
        List of ForgeRevision objects, most recent first
    """
    # Group by forge_sha
    by_sha: dict[str | None, list[WorkflowRun]] = {}
    for run in runs:
        key = run.forge_sha or f"unknown-{run.head_sha[:7]}"
        if key not in by_sha:
            by_sha[key] = []
        by_sha[key].append(run)

    # Convert to ForgeRevision objects
    revisions = []
    for sha, sha_runs in by_sha.items():
        # Find latest timestamp and run URL
        latest = max(sha_runs, key=lambda r: r.updated_at)
        forge_run_url = None
        if latest.forge_run_id:
            forge_run_url = f"https://github.com/mithro/gf180mcu-sram-forge/actions/runs/{latest.forge_run_id}"

        revisions.append(ForgeRevision(
            forge_sha=sha if not sha.startswith("unknown-") else sha,
            forge_run_url=forge_run_url,
            timestamp=latest.updated_at,
            runs=sha_runs,
        ))

    # Sort by timestamp, most recent first
    revisions.sort(key=lambda r: r.timestamp, reverse=True)
    return revisions


def fetch_all_status(repos: list[DownstreamRepo], limit: int = 5) -> StatusReport:
    """Fetch status for all downstream repos and create report.

    Args:
        repos: List of downstream repo configs
        limit: Max runs per repo

    Returns:
        Complete StatusReport
    """
    all_runs = []
    for repo in repos:
        try:
            runs = fetch_repo_status(repo, limit)
            all_runs.extend(runs)
        except subprocess.CalledProcessError as e:
            # Log error but continue with other repos
            print(f"Warning: Failed to fetch status for {repo.full_name}: {e}")

    revisions = group_by_forge_revision(all_runs)

    return StatusReport(
        generated_at=datetime.now(timezone.utc),
        revisions=revisions,
    )
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest sram_forge/tests/test_status_fetcher.py -v`
Expected: PASS (3 tests)

**Step 5: Commit**

```bash
git add sram_forge/status/fetcher.py sram_forge/tests/test_status_fetcher.py
git commit -m "feat: add status fetcher module

Fetches workflow runs via gh CLI, extracts forge SHA from
commit messages, groups runs by revision."
```

---

## Task 6: Create Status Reporter (Terminal/Markdown/JSON)

**Files:**
- Create: `sram_forge/status/reporter.py`
- Create: `sram_forge/tests/test_status_reporter.py`

**Step 1: Write the failing test**

Create `sram_forge/tests/test_status_reporter.py`:

```python
"""Tests for status reporter."""

from datetime import datetime, timezone

import pytest

from sram_forge.status.models import WorkflowRun, ForgeRevision, StatusReport
from sram_forge.status.reporter import format_terminal, format_markdown, format_json


@pytest.fixture
def sample_report():
    """Create a sample status report for testing."""
    now = datetime.now(timezone.utc)
    runs = [
        WorkflowRun(
            repo="mithro/gf180mcu-ic-1x1-sram-u8b24k",
            sram="u8b24k", slot="1x1", workflow_name="CI",
            status="completed", conclusion="success", run_id=1, head_sha="aaa",
            updated_at=now, html_url="http://example.com/1",
            forge_sha="abc123", forge_run_id=100
        ),
        WorkflowRun(
            repo="mithro/gf180mcu-ic-0p5x0p5-sram-u8b3k",
            sram="u8b3k", slot="0p5x0p5", workflow_name="CI",
            status="completed", conclusion="failure", run_id=2, head_sha="bbb",
            updated_at=now, html_url="http://example.com/2",
            forge_sha="abc123", forge_run_id=100
        ),
    ]
    revision = ForgeRevision(
        forge_sha="abc123",
        forge_run_url="http://example.com/runs/100",
        timestamp=now,
        runs=runs
    )
    return StatusReport(generated_at=now, revisions=[revision])


def test_format_terminal(sample_report):
    """Terminal output contains key info."""
    result = format_terminal(sample_report)

    assert "abc123" in result  # Forge SHA
    assert "u8b24k" in result  # SRAM name
    assert "u8b3k" in result
    assert "1/2" in result  # Summary


def test_format_markdown(sample_report):
    """Markdown output is valid table format."""
    result = format_markdown(sample_report)

    assert "|" in result  # Table format
    assert "abc123" in result
    assert "u8b24k" in result


def test_format_json(sample_report):
    """JSON output is valid JSON."""
    import json

    result = format_json(sample_report)
    parsed = json.loads(result)

    assert "generated_at" in parsed
    assert "revisions" in parsed
    assert len(parsed["revisions"]) == 1
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest sram_forge/tests/test_status_reporter.py -v`
Expected: FAIL with "cannot import name 'format_terminal'"

**Step 3: Write the reporter module**

Create `sram_forge/status/reporter.py`:

```python
"""Format status reports for different outputs."""

from datetime import datetime, timezone

from sram_forge.status.models import StatusReport, ForgeRevision, WorkflowRun


def _time_ago(dt: datetime) -> str:
    """Format datetime as relative time string."""
    now = datetime.now(timezone.utc)
    diff = now - dt

    seconds = diff.total_seconds()
    if seconds < 60:
        return "just now"
    elif seconds < 3600:
        mins = int(seconds / 60)
        return f"{mins}m ago"
    elif seconds < 86400:
        hours = int(seconds / 3600)
        return f"{hours}h ago"
    else:
        days = int(seconds / 86400)
        return f"{days}d ago"


def _status_emoji(run: WorkflowRun) -> str:
    """Get emoji for run status."""
    if run.status != "completed":
        return "üîÑ"
    return "‚úÖ" if run.is_success else "‚ùå"


def format_terminal(report: StatusReport) -> str:
    """Format report for terminal output with colors."""
    lines = [
        "sram-forge IC Status",
        "=" * 50,
        f"Last updated: {report.generated_at.strftime('%Y-%m-%d %H:%M UTC')}",
        "",
    ]

    for rev in report.revisions:
        sha_short = rev.forge_sha[:7] if len(rev.forge_sha) > 7 else rev.forge_sha
        status_indicator = "‚úÖ" if rev.all_passing else "‚ùå"

        lines.append(f"üì¶ {sha_short} ({_time_ago(rev.timestamp)})  {rev.summary} {status_indicator}")

        # Show SRAMs on one line
        sram_statuses = [f"{_status_emoji(r)} {r.sram}" for r in rev.runs]
        lines.append(f"   {' '.join(sram_statuses)}")
        lines.append("")

    # Summary
    if report.revisions:
        latest = report.revisions[0]
        if latest.all_passing:
            lines.append("Summary: Latest revision passing ‚úÖ")
        else:
            lines.append(f"Summary: Latest revision {latest.summary} ‚ùå")

    return "\n".join(lines)


def format_markdown(report: StatusReport) -> str:
    """Format report as markdown table."""
    lines = [
        "## sram-forge IC Status",
        "",
        f"*Last updated: {report.generated_at.strftime('%Y-%m-%d %H:%M UTC')}*",
        "",
    ]

    for rev in report.revisions:
        sha_short = rev.forge_sha[:7] if len(rev.forge_sha) > 7 else rev.forge_sha
        sha_link = f"[`{sha_short}`]({rev.forge_run_url})" if rev.forge_run_url else f"`{sha_short}`"

        status_indicator = "‚úÖ" if rev.all_passing else "‚ùå"
        lines.append(f"### Revision {sha_link} ({rev.summary} {status_indicator})")
        lines.append("")
        lines.append("| SRAM | Slot | Status | Workflow | Commit |")
        lines.append("|------|------|--------|----------|--------|")

        for run in rev.runs:
            status = f"{_status_emoji(run)} {run.conclusion or run.status}"
            commit_link = f"[`{run.head_sha[:7]}`]({run.html_url})"
            lines.append(f"| {run.sram} | {run.slot} | {status} | {run.workflow_name} | {commit_link} |")

        lines.append("")

    return "\n".join(lines)


def format_json(report: StatusReport) -> str:
    """Format report as JSON."""
    return report.model_dump_json(indent=2)
```

**Step 4: Run tests to verify they pass**

Run: `uv run pytest sram_forge/tests/test_status_reporter.py -v`
Expected: PASS (3 tests)

**Step 5: Commit**

```bash
git add sram_forge/status/reporter.py sram_forge/tests/test_status_reporter.py
git commit -m "feat: add status reporter for terminal/markdown/JSON output"
```

---

## Task 7: Create HTML Template and Generator

**Files:**
- Create: `sram_forge/status/templates/status_page.html.j2`
- Modify: `sram_forge/status/reporter.py`
- Modify: `sram_forge/tests/test_status_reporter.py`

**Step 1: Write the failing test**

Add to `sram_forge/tests/test_status_reporter.py`:

```python
def test_format_html(sample_report):
    """HTML output is valid HTML."""
    from sram_forge.status.reporter import format_html

    result = format_html(sample_report)

    assert "<!DOCTYPE html>" in result
    assert "abc123" in result
    assert "u8b24k" in result
    assert "<script>" in result  # Has JS
    assert "<style>" in result   # Has CSS
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest sram_forge/tests/test_status_reporter.py::test_format_html -v`
Expected: FAIL with "cannot import name 'format_html'"

**Step 3: Create the HTML template**

Create `sram_forge/status/templates/status_page.html.j2`:

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>sram-forge IC Status</title>
    <style>
        :root {
            --bg: #1a1a2e;
            --card-bg: #16213e;
            --text: #eee;
            --text-muted: #888;
            --success: #4ade80;
            --failure: #f87171;
            --border: #334155;
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg);
            color: var(--text);
            padding: 2rem;
            line-height: 1.6;
        }
        .container { max-width: 900px; margin: 0 auto; }
        header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 2rem;
            flex-wrap: wrap;
            gap: 1rem;
        }
        h1 { font-size: 1.5rem; }
        .timestamp { color: var(--text-muted); font-size: 0.9rem; }
        .filters {
            display: flex;
            gap: 0.5rem;
        }
        .filter-btn {
            padding: 0.5rem 1rem;
            border: 1px solid var(--border);
            background: transparent;
            color: var(--text);
            border-radius: 4px;
            cursor: pointer;
            transition: all 0.2s;
        }
        .filter-btn:hover, .filter-btn.active {
            background: var(--border);
        }
        .summary {
            background: var(--card-bg);
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 1.5rem;
            text-align: center;
            font-size: 1.2rem;
        }
        .summary.passing { border-left: 4px solid var(--success); }
        .summary.failing { border-left: 4px solid var(--failure); }
        .revision {
            background: var(--card-bg);
            border-radius: 8px;
            margin-bottom: 1rem;
            overflow: hidden;
        }
        .revision-header {
            padding: 1rem;
            cursor: pointer;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-bottom: 1px solid var(--border);
        }
        .revision-header:hover { background: rgba(255,255,255,0.05); }
        .revision.failing .revision-header { border-left: 4px solid var(--failure); }
        .revision.passing .revision-header { border-left: 4px solid var(--success); }
        .sha { font-family: monospace; font-weight: bold; }
        .sha a { color: var(--text); text-decoration: none; }
        .sha a:hover { text-decoration: underline; }
        .time-ago { color: var(--text-muted); font-size: 0.9rem; }
        .status-summary { font-weight: bold; }
        .status-summary.passing { color: var(--success); }
        .status-summary.failing { color: var(--failure); }
        .sram-chips {
            display: flex;
            gap: 0.75rem;
            padding: 1rem;
            flex-wrap: wrap;
        }
        .sram-chip {
            padding: 0.25rem 0.75rem;
            border-radius: 4px;
            font-size: 0.9rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        .sram-chip.success { background: rgba(74, 222, 128, 0.2); }
        .sram-chip.failure { background: rgba(248, 113, 113, 0.2); }
        .sram-chip a { color: inherit; text-decoration: none; }
        .sram-chip a:hover { text-decoration: underline; }
        .revision-details {
            display: none;
            padding: 1rem;
            border-top: 1px solid var(--border);
        }
        .revision.expanded .revision-details { display: block; }
        table { width: 100%; border-collapse: collapse; }
        th, td { padding: 0.5rem; text-align: left; border-bottom: 1px solid var(--border); }
        th { color: var(--text-muted); font-weight: normal; }
        td a { color: var(--text); }
        .hidden { display: none !important; }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <div>
                <h1>sram-forge IC Status</h1>
                <div class="timestamp">Last updated: {{ report.generated_at.strftime('%Y-%m-%d %H:%M UTC') }}</div>
            </div>
            <div class="filters">
                <button class="filter-btn active" data-filter="all">All</button>
                <button class="filter-btn" data-filter="passing">Passing</button>
                <button class="filter-btn" data-filter="failing">Failing</button>
            </div>
        </header>

        {% if report.revisions %}
        {% set latest = report.revisions[0] %}
        <div class="summary {{ 'passing' if latest.all_passing else 'failing' }}">
            Latest: {{ latest.summary }} {{ '‚úÖ' if latest.all_passing else '‚ùå' }}
        </div>
        {% endif %}

        <div id="revisions">
        {% for rev in report.revisions %}
            <div class="revision {{ 'passing' if rev.all_passing else 'failing' }}" data-status="{{ 'passing' if rev.all_passing else 'failing' }}">
                <div class="revision-header" onclick="toggleRevision(this)">
                    <div>
                        <span class="sha">
                            {% if rev.forge_run_url %}
                            <a href="{{ rev.forge_run_url }}" target="_blank">üì¶ {{ rev.forge_sha[:7] }}</a>
                            {% else %}
                            üì¶ {{ rev.forge_sha[:7] }}
                            {% endif %}
                        </span>
                        <span class="time-ago">({{ time_ago(rev.timestamp) }})</span>
                    </div>
                    <span class="status-summary {{ 'passing' if rev.all_passing else 'failing' }}">
                        {{ rev.summary }} {{ '‚úÖ' if rev.all_passing else '‚ùå' }}
                    </span>
                </div>
                <div class="sram-chips">
                    {% for run in rev.runs %}
                    <div class="sram-chip {{ 'success' if run.is_success else 'failure' }}">
                        {{ '‚úÖ' if run.is_success else '‚ùå' }}
                        <a href="https://github.com/{{ run.repo }}/actions" target="_blank">{{ run.sram }}</a>
                    </div>
                    {% endfor %}
                </div>
                <div class="revision-details">
                    <table>
                        <thead>
                            <tr>
                                <th>SRAM</th>
                                <th>Slot</th>
                                <th>Status</th>
                                <th>Workflow</th>
                                <th>Commit</th>
                            </tr>
                        </thead>
                        <tbody>
                            {% for run in rev.runs %}
                            <tr>
                                <td>{{ run.sram }}</td>
                                <td>{{ run.slot }}</td>
                                <td>{{ '‚úÖ' if run.is_success else '‚ùå' }} {{ run.conclusion or run.status }}</td>
                                <td>{{ run.workflow_name }}</td>
                                <td><a href="{{ run.html_url }}" target="_blank">{{ run.head_sha[:7] }}</a></td>
                            </tr>
                            {% endfor %}
                        </tbody>
                    </table>
                </div>
            </div>
        {% endfor %}
        </div>
    </div>

    <script>
        function toggleRevision(header) {
            header.parentElement.classList.toggle('expanded');
        }

        document.querySelectorAll('.filter-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                document.querySelectorAll('.filter-btn').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');

                const filter = btn.dataset.filter;
                document.querySelectorAll('.revision').forEach(rev => {
                    if (filter === 'all') {
                        rev.classList.remove('hidden');
                    } else {
                        rev.classList.toggle('hidden', rev.dataset.status !== filter);
                    }
                });
            });
        });
    </script>
</body>
</html>
```

**Step 4: Add format_html to reporter**

Add to `sram_forge/status/reporter.py`:

```python
from pathlib import Path
from jinja2 import Environment, FileSystemLoader


def format_html(report: StatusReport) -> str:
    """Format report as self-contained HTML page."""
    template_dir = Path(__file__).parent / "templates"
    env = Environment(loader=FileSystemLoader(template_dir))
    env.globals["time_ago"] = _time_ago

    template = env.get_template("status_page.html.j2")
    return template.render(report=report)
```

**Step 5: Run tests to verify they pass**

Run: `uv run pytest sram_forge/tests/test_status_reporter.py -v`
Expected: PASS (4 tests)

**Step 6: Commit**

```bash
git add sram_forge/status/templates/status_page.html.j2 sram_forge/status/reporter.py sram_forge/tests/test_status_reporter.py
git commit -m "feat: add HTML status page generator

Self-contained HTML with CSS and JS for interactive status display.
Filter by passing/failing, expandable details."
```

---

## Task 8: Add CLI Commands

**Files:**
- Modify: `sram_forge/cli/main.py`
- Modify: `sram_forge/tests/test_cli.py`

**Step 1: Write the failing test**

Add to `sram_forge/tests/test_cli.py`:

```python
def test_downstream_list(cli_runner):
    """downstream list shows all repos."""
    result = cli_runner.invoke(main, ["downstream", "list"])

    assert result.exit_code == 0
    assert "u8b24k" in result.output
    assert "u8b3k" in result.output


def test_downstream_matrix(cli_runner):
    """downstream matrix outputs JSON."""
    import json

    result = cli_runner.invoke(main, ["downstream", "matrix"])

    assert result.exit_code == 0
    data = json.loads(result.output)
    assert "include" in data
    assert len(data["include"]) == 4
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest sram_forge/tests/test_cli.py::test_downstream_list -v`
Expected: FAIL with "No such command 'downstream'"

**Step 3: Add the CLI commands**

Add to `sram_forge/cli/main.py`:

```python
import json
from sram_forge.db.loader import load_downstream_repos
from sram_forge.status.fetcher import fetch_all_status
from sram_forge.status.reporter import format_terminal, format_markdown, format_json, format_html


@main.group()
def downstream():
    """Manage downstream IC repositories."""
    pass


@downstream.command("list")
def downstream_list():
    """List all downstream IC repositories."""
    data_dir = get_bundled_data_dir()
    repos = load_downstream_repos(data_dir / "downstream_repos.yaml")

    click.echo("Downstream IC Repositories:")
    click.echo("-" * 60)
    for repo in repos:
        click.echo(f"  {repo.sram:8} {repo.slot:8} {repo.full_name}")


@downstream.command("matrix")
def downstream_matrix():
    """Output repository list as JSON matrix for GitHub Actions."""
    data_dir = get_bundled_data_dir()
    repos = load_downstream_repos(data_dir / "downstream_repos.yaml")

    matrix = {
        "include": [
            {
                "sram": r.sram,
                "slot": r.slot,
                "config": r.config,
                "repo": r.full_name,
                "secret": r.deploy_key_secret,
            }
            for r in repos
        ]
    }
    click.echo(json.dumps(matrix))


@downstream.command("status")
@click.option("--format", "fmt", type=click.Choice(["terminal", "md", "json", "html"]), default="terminal")
@click.option("--output", "-o", type=click.Path(), help="Output file (required for HTML)")
def downstream_status(fmt: str, output: str | None):
    """Show GitHub Actions status for all downstream repos."""
    data_dir = get_bundled_data_dir()
    repos = load_downstream_repos(data_dir / "downstream_repos.yaml")

    click.echo("Fetching status...", err=True)
    report = fetch_all_status(repos)

    if fmt == "terminal":
        click.echo(format_terminal(report))
    elif fmt == "md":
        click.echo(format_markdown(report))
    elif fmt == "json":
        click.echo(format_json(report))
    elif fmt == "html":
        if not output:
            click.echo("Error: --output required for HTML format", err=True)
            raise SystemExit(1)
        Path(output).write_text(format_html(report))
        click.echo(f"Wrote HTML to {output}", err=True)
```

Also add the Path import at the top if not present.

**Step 4: Run tests to verify they pass**

Run: `uv run pytest sram_forge/tests/test_cli.py -v -k downstream`
Expected: PASS

**Step 5: Commit**

```bash
git add sram_forge/cli/main.py sram_forge/tests/test_cli.py
git commit -m "feat: add downstream CLI commands

- downstream list: show all downstream repos
- downstream matrix: JSON output for GitHub Actions
- downstream status: aggregated status with multiple formats"
```

---

## Task 9: Update Downstream Workflow to Use Dynamic Matrix

**Files:**
- Modify: `.github/workflows/update-downstream.yml`

**Step 1: Update the workflow**

Replace `.github/workflows/update-downstream.yml`:

```yaml
name: Update Downstream Repos

on:
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      force:
        description: 'Force update even if no changes'
        required: false
        default: 'false'
        type: boolean

jobs:
  load-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Checkout sram-forge
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "0.5.x"

      - name: Set up Python
        run: uv python install 3.11

      - name: Install sram-forge
        run: uv sync

      - name: Generate matrix
        id: set-matrix
        run: echo "matrix=$(uv run sram-forge downstream matrix)" >> $GITHUB_OUTPUT

  update-downstream:
    needs: load-matrix
    name: Update ${{ matrix.sram }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.load-matrix.outputs.matrix) }}

    steps:
      - name: Checkout sram-forge
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "0.5.x"

      - name: Set up Python
        run: uv python install 3.11

      - name: Install sram-forge
        run: uv sync

      - name: Configure SSH for downstream repo
        env:
          DEPLOY_KEY: ${{ secrets[matrix.secret] }}
        run: |
          mkdir -p ~/.ssh
          echo "$DEPLOY_KEY" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan github.com >> ~/.ssh/known_hosts
          git config --global core.sshCommand 'ssh -i ~/.ssh/deploy_key'

      - name: Clone downstream repo
        run: |
          git clone git@github.com:${{ matrix.repo }}.git downstream

      - name: Generate updated files
        run: |
          uv run sram-forge gen ${{ matrix.config }} -o downstream

      - name: Check for changes
        id: check_changes
        run: |
          cd downstream
          git add -A
          if git diff --cached --quiet; then
            echo "changed=false" >> $GITHUB_OUTPUT
            echo "No changes detected"
          else
            echo "changed=true" >> $GITHUB_OUTPUT
            echo "Changes detected:"
            git diff --cached --stat
          fi

      - name: Commit and push changes
        if: steps.check_changes.outputs.changed == 'true' || github.event.inputs.force == 'true'
        run: |
          cd downstream
          git config user.name "sram-forge bot"
          git config user.email "sram-forge-bot@users.noreply.github.com"
          git commit -m "chore: update generated files from sram-forge

          Source commit: ${{ github.sha }}
          Workflow run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          git push

      - name: Trigger downstream build
        if: steps.check_changes.outputs.changed == 'true' || github.event.inputs.force == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Dispatch workflow in downstream repo if it exists
          gh workflow run build.yml --repo ${{ matrix.repo }} 2>/dev/null || echo "No build workflow to trigger"
```

**Step 2: Commit**

```bash
git add .github/workflows/update-downstream.yml
git commit -m "refactor: use dynamic matrix from downstream_repos.yaml

Matrix now loaded via sram-forge downstream matrix command.
Single source of truth for downstream repo configuration."
```

---

## Task 10: Create Status Page Workflow

**Files:**
- Create: `.github/workflows/status-page.yml`

**Step 1: Create the workflow**

Create `.github/workflows/status-page.yml`:

```yaml
name: Update Status Page

on:
  schedule:
    - cron: '0 */4 * * *'  # Every 4 hours
  workflow_dispatch:
  workflow_run:
    workflows: ["Update Downstream Repos"]
    types: [completed]

jobs:
  update-status:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout sram-forge
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "0.5.x"

      - name: Set up Python
        run: uv python install 3.11

      - name: Install sram-forge
        run: uv sync

      - name: Generate status page
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          mkdir -p _site
          uv run sram-forge downstream status --format html -o _site/index.html
          uv run sram-forge downstream status --format json -o _site/status.json

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./_site
          publish_branch: gh-pages
```

**Step 2: Commit**

```bash
git add .github/workflows/status-page.yml
git commit -m "feat: add GitHub Actions workflow for status page

Runs every 4 hours and after downstream updates.
Publishes HTML and JSON to GitHub Pages."
```

---

## Task 11: Final Integration Test

**Step 1: Run full test suite**

```bash
uv run pytest -v
```

Expected: All tests pass

**Step 2: Test CLI commands manually**

```bash
# List repos
uv run sram-forge downstream list

# Get matrix JSON
uv run sram-forge downstream matrix

# Verify JSON is valid
uv run sram-forge downstream matrix | jq .

# Test status (requires gh auth)
uv run sram-forge downstream status

# Generate HTML
uv run sram-forge downstream status --format html -o /tmp/status.html
```

**Step 3: Verify HTML in browser**

Open `/tmp/status.html` and verify:
- Page loads without errors
- Shows revision information
- Filter buttons work
- Expandable details work

**Step 4: Final commit if any fixes needed**

---

## Summary

**New files created:**
- `sram_forge/db/data/downstream_repos.yaml`
- `sram_forge/models/downstream.py`
- `sram_forge/status/__init__.py`
- `sram_forge/status/models.py`
- `sram_forge/status/fetcher.py`
- `sram_forge/status/reporter.py`
- `sram_forge/status/templates/status_page.html.j2`
- `.github/workflows/status-page.yml`

**Modified files:**
- `sram_forge/models/__init__.py`
- `sram_forge/db/loader.py`
- `sram_forge/cli/main.py`
- `.github/workflows/update-downstream.yml`

**Test files created:**
- `sram_forge/tests/test_models_downstream.py`
- `sram_forge/tests/test_status_models.py`
- `sram_forge/tests/test_status_fetcher.py`
- `sram_forge/tests/test_status_reporter.py`
